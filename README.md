# Projeto de Regress√£o Linear, Ridge e Lasso

Este projeto tem como objetivo aplicar t√©cnicas de **regress√£o linear** para prever o pre√ßo de ve√≠culos, seguindo uma sequ√™ncia estruturada de pr√©-processamento, modelagem, avalia√ß√£o e interpreta√ß√£o dos resultados. O trabalho foi desenvolvido com base no dataset Car Price Prediction, disponibilizado no Kaggle. O foco do projeto n√£o √© uma an√°lise explorat√≥ria aprofundada, mas sim compreender o dataset, preparar os dados corretamente,
aplicar um modelo de regress√£o linear, avaliar seu desempenho, e visualizar a rela√ß√£o entre a vari√°vel mais correlacionada e o pre√ßo.

---

## üìÅ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ preprocessamento.py            # Pr√©-processamento e correla√ß√£o
‚îú‚îÄ‚îÄ regressao_linear_simples.py    # Regress√£o linear simples
‚îú‚îÄ‚îÄ linear_ridge_lasso.py          # Linear vs Ridge vs Lasso
‚îú‚îÄ‚îÄ coeficientes.py                # Coeficientes e sele√ß√£o de atributos
‚îú‚îÄ‚îÄ CarPrice_dataset_ajustado.csv  # Dataset ajustado
‚îú‚îÄ‚îÄ imagem                         # Imagens de resultados
‚îî‚îÄ‚îÄ README.md
```

---
## üìÇ Dataset

Fonte: Kaggle

Link: https://www.kaggle.com/datasets/hellbuoy/car-price-prediction

Nome do arquivo original: CarPrice_Assignment.csv

O dataset cont√©m informa√ß√µes de diferentes autom√≥veis, incluindo caracter√≠sticas como:

* tipo de combust√≠vel

* tamanho do motor

* pot√™ncia

* consumo

* dimens√µes do ve√≠culo

* pre√ßo (vari√°vel alvo)

---

## Bibliotecas utilizadas

Este projeto foi desenvolvido em Python utilizando bibliotecas amplamente empregadas em an√°lise de dados e aprendizado de m√°quina, conforme descrito abaixo:

---

Pandas: Biblioteca utilizada para carregamento, manipula√ß√£o e an√°lise de dados tabulares.
Permite ler arquivos CSV, tratar colunas, selecionar vari√°veis e realizar an√°lises estat√≠sticas b√°sicas.
```python
import pandas as pd
```
Matplotlib: Biblioteca fundamental para cria√ß√£o de gr√°ficos em Python.
Foi utilizada para plotar gr√°ficos de dispers√£o, retas de regress√£o e gr√°ficos de import√¢ncia dos atributos.
```python
import seaborn as pd
```
Seaborn: Biblioteca de visualiza√ß√£o estat√≠stica baseada no matplotlib.
Facilita a cria√ß√£o de gr√°ficos mais elegantes, como mapas de correla√ß√£o, boxplots e distribui√ß√µes.
```python
import matplotlib.pyplot as plt
```
NumPy: Biblioteca fundamental para opera√ß√µes num√©ricas e matem√°ticas em Python.
Foi utilizada para c√°lculos como o RMSE, manipula√ß√£o de arrays e opera√ß√µes vetoriais.
```python
import numpy as np
```
train_test_split: Fun√ß√£o do scikit-learn utilizada para dividir o dataset em conjuntos de treino e teste, garantindo uma avalia√ß√£o adequada do modelo.
```python
from sklearn.model_selection import train_test_split
```
StandardScaler: Utilizada para padroniza√ß√£o dos dados num√©ricos, fazendo com que todas as vari√°veis tenham m√©dia 0 e desvio padr√£o 1.
Essa etapa √© essencial para modelos sens√≠veis √† escala, como Ridge e Lasso.
```python
from sklearn.preprocessing import StandardScaler
```
LinearRegression: Modelo de Regress√£o Linear do scikit-learn.
Foi aplicado tanto na regress√£o linear simples quanto na regress√£o linear m√∫ltipla.
```python
from sklearn.linear_model import LinearRegression
```
Ridge Regression: Modelo de regress√£o linear com regulariza√ß√£o L2, utilizado para reduzir overfitting e controlar a magnitude dos coeficientes.
```python
from sklearn.linear_model import Ridge
```
Lasso Regression: Modelo de regress√£o linear com regulariza√ß√£o L1, capaz de zerar coeficientes, sendo √∫til para sele√ß√£o de atributos e an√°lise de import√¢ncia das vari√°veis.
```python
from sklearn.linear_model import Lasso
```
cross_val_score: Fun√ß√£o utilizada para aplicar valida√ß√£o cruzada (cross-validation), permitindo avaliar o desempenho dos modelos de forma mais robusta.
```python
from sklearn.model_selection import cross_val_score
```
M√©tricas de Avalia√ß√£o: Foram utilizadas m√©tricas para avaliar o desempenho dos modelos de regress√£o:
RMSE (Root Mean Squared Error): mede o erro m√©dio das previs√µes.
R¬≤ (Coeficiente de Determina√ß√£o): indica o quanto o modelo explica a variabilidade da vari√°vel alvo.
```python
from sklearn.metrics import mean_squared_error, r2_score
```

---

## Pr√©-processamento e Correla√ß√£o

**Arquivo:** `preprocessamento.py`

Nesta etapa inicial, foi realizado o preparo dos dados para a modelagem:

1. O dataset original foi carregado.

Inicialmente, o dataset bruto foi carregado utilizando a biblioteca Pandas, e foram realizadas inspe√ß√µes b√°sicas para compreender sua estrutura:
* Visualiza√ß√£o das primeiras linhas do dataset (head)
* Verifica√ß√£o dos tipos de dados de cada coluna
* Verifica√ß√£o de valores ausentes (missing values)
Essa etapa permitiu confirmar que o dataset n√£o possui valores nulos, eliminando a necessidade de t√©cnicas de imputa√ß√£o.

2. Tratamento de vari√°veis categ√≥ricas.

O dataset cont√©m diversas vari√°veis categ√≥ricas, como tipo de combust√≠vel, carroceria, tipo de motor e sistema de combust√≠vel. Como modelos de regress√£o n√£o trabalham diretamente com dados categ√≥ricos em formato textual, foi necess√°rio convert√™-los para valores num√©ricos.
As seguintes colunas categ√≥ricas foram identificadas:
* CarName
* fueltype
* aspiration
* doornumber
* carbody
* drivewheel
* enginelocation
* enginetype
* cylindernumber
* fuelsystem
  
Para isso, foi utilizado o m√©todo `pd.factorize()`, que transforma cada categoria em um valor inteiro √∫nico. Esse m√©todo foi escolhido por ser simples e suficiente para esta etapa explorat√≥ria e de modelagem inicial.
Ap√≥s a convers√£o, todas as colunas do dataset passaram a possuir valores num√©ricos.

3. An√°lise de Correla√ß√£o e matriz de correla√ß√£o entre as vari√°veis num√©ricas e a vari√°vel-alvo (`price`).

Com os dados totalmente num√©ricos, foi realizada uma an√°lise de correla√ß√£o entre todas as vari√°veis e a vari√°vel alvo price.
Essa an√°lise teve como objetivo:
Identificar quais atributos possuem maior rela√ß√£o com o pre√ßo dos ve√≠culos e auxiliar na sele√ß√£o das vari√°veis mais relevantes para os modelos de regress√£o.
As correla√ß√µes foram ordenadas de forma decrescente, permitindo identificar rapidamente as vari√°veis mais correlacionadas positiva ou negativamente com o pre√ßo.

```
Correla√ß√£o das vari√°veis com Price:
 price               1.000000
enginesize          0.874145
curbweight          0.835305
horsepower          0.808139
carwidth            0.759325
carlength           0.682920
...                   ...
fuelsystem         -0.122118
drivewheel         -0.577992
citympg            -0.685751
highwaympg         -0.697599
```
Al√©m da correla√ß√£o individual com a vari√°vel alvo, foi constru√≠da uma matriz de correla√ß√£o completa, considerando todas as colunas num√©ricas do dataset.
Foi utilizado o m√©todo de correla√ß√£o Spearman, por ser mais robusto a rela√ß√µes n√£o lineares e valores extremos.

![Matriz de Correla√ß√£o](imagem/matriz_correla√ß√£o.png)

4. O dataset final pr√©-processado foi salvo no arquivo `regressao_ajustado.csv`.

Essa etapa √© fundamental para garantir qualidade dos dados e evitar vieses nos modelos.

---

## Regress√£o Linear Simples

**Arquivo:** `regressao_linear_simples.py`

Nesta etapa, foi aplicada a regress√£o linear simples com o objetivo de entender a rela√ß√£o entre uma vari√°vel explicativa e o pre√ßo.
Ap√≥s a etapa de pr√©-processamento e an√°lise de correla√ß√£o, foi aplicada uma Regress√£o Linear Simples com o objetivo de modelar a rela√ß√£o entre o pre√ßo dos ve√≠culos (`price`) e a vari√°vel `enginesize`, identificada como a mais correlacionada com a vari√°vel alvo.

1. A vari√°vel mais correlacionada com o pre√ßo foi escolhida para o modelo.
A vari√°vel `enginesize` foi selecionada como √∫nica vari√°vel explicativa do modelo, enquanto `price` foi definida como vari√°vel alvo. A escolha dessa feature foi baseada na an√°lise pr√©via de correla√ß√£o, que indicou uma forte rela√ß√£o positiva entre essas duas vari√°veis.

2. Uso do LinearRegression
O modelo de Regress√£o Linear Simples foi treinado utilizando o algoritmo LinearRegression da biblioteca scikit-learn. Inicialmente, o modelo foi ajustado utilizando todo o conjunto de dados com a finalidade de visualizar a rela√ß√£o linear entre as vari√°veis por meio de um gr√°fico.

4. Um gr√°fico foi gerado exibindo os pontos reais e a reta de regress√£o ajustada.

![Reta de Regress√£o](imagem/reta_de_regress√£o.png).

Foi gerado um gr√°fico de dispers√£o contendo os valores reais do dataset, juntamente com a reta de regress√£o estimada pelo modelo. Essa visualiza√ß√£o permite observar claramente a tend√™ncia de crescimento do pre√ßo conforme o tamanho do motor aumenta, confirmando o comportamento identificado na an√°lise de correla√ß√£o.

5. O desempenho do modelo foi avaliado utilizando as m√©tricas **RMSE** e **R¬≤**.

Para avaliar o desempenho do modelo de forma adequada, o dataset foi dividido em conjuntos de treinamento (80%) e teste (20%). Essa separa√ß√£o garante que a avalia√ß√£o seja realizada em dados n√£o utilizados durante o treinamento do modelo. Ap√≥s o treinamento, o modelo foi aplicado ao conjunto de teste, e seu desempenho foi avaliado utilizando duas m√©tricas amplamente empregadas em problemas de regress√£o:
* RMSE (Root Mean Squared Error), que mede o erro m√©dio das previs√µes do modelo.
O RMSE foi 3932.61. Considerando que o pre√ßo m√©dio dos ve√≠culos no dataset est√° em torno de 13.000, esse erro pode ser considerado moderado, sendo esperado para um modelo simples que utiliza apenas uma √∫nica vari√°vel explicativa.

* R¬≤ (Coeficiente de Determina√ß√£o), que indica a propor√ß√£o da variabilidade do pre√ßo explicada pela regress√£o linear simples.
O valor de R¬≤ = 0.8041 indica que aproximadamente 80% da varia√ß√£o do pre√ßo dos ve√≠culos pode ser explicada apenas pelo tamanho do motor. Esse resultado evidencia uma forte rela√ß√£o linear entre enginesize e price, confirmando a relev√¢ncia dessa vari√°vel como principal fator explicativo do pre√ßo no dataset.

Essa an√°lise fornece uma visualiza√ß√£o clara da rela√ß√£o linear entre a vari√°vel escolhida e o pre√ßo.

---

## Compara√ß√£o: Linear vs Ridge vs Lasso

**Arquivo:** `linear_ridge_lasso.py`

Ap√≥s a aplica√ß√£o da regress√£o linear simples, foram avaliados modelos de regress√£o mais robustos com o objetivo de comparar o desempenho da regress√£o linear tradicional com m√©todos que utilizam regulariza√ß√£o, especificamente Ridge e Lasso.

Essa etapa teve como foco analisar se a inclus√£o de regulariza√ß√£o poderia melhorar a capacidade de generaliza√ß√£o do modelo e reduzir poss√≠veis problemas de overfitting.

1. Prepara√ß√£o dos Dados

O dataset utilizado foi o CarPrice_dataset_ajustado.csv, previamente pr√©-processado. Para manter a compara√ß√£o justa entre os modelos, foi utilizada apenas a vari√°vel enginesize, mantendo o mesmo cen√°rio da regress√£o linear simples.

2. Uso de Pipeline e Padroniza√ß√£o

Cada modelo foi implementado utilizando um Pipeline, que integra duas etapas principais:
* Padroniza√ß√£o dos dados por meio do StandardScaler, garantindo que a vari√°vel explicativa possua m√©dia zero e desvio padr√£o igual a um.
* Treinamento do modelo de regress√£o, seja Linear, Ridge ou Lasso.
  
O uso de pipelines assegura que o processo de padroniza√ß√£o seja corretamente aplicado em cada itera√ß√£o da valida√ß√£o cruzada, evitando vazamento de dados (data leakage).

3. AValida√ß√£o Cruzada (Cross-Validation)

Para avaliar o desempenho dos modelos de forma mais robusta, foi aplicada valida√ß√£o cruzada com 5 folds. Nesse processo, o dataset √© dividido em cinco partes, e cada modelo √© treinado e avaliado cinco vezes, utilizando diferentes subconjuntos de dados para treino e teste.

Foram utilizadas duas m√©tricas de avalia√ß√£o:
* RMSE M√©dio, calculado a partir do erro quadr√°tico m√©dio negativo retornado pelo cross_val_score.
* R¬≤ M√©dio, que mede o poder explicativo m√©dio do modelo ao longo dos folds.

Essa abordagem reduz a depend√™ncia de uma √∫nica divis√£o treino-teste e fornece uma estimativa mais confi√°vel do desempenho dos modelos.

4. Os resultados foram organizados em uma tabela comparativa.

A ordena√ß√£o dos modelos pelo menor RMSE m√©dio permite identificar qual abordagem apresentou melhor desempenho em termos de erro de previs√£o.
```
Tabela Comparativa dos Modelos:

              Modelo   RMSE M√©dio  R¬≤ M√©dio
1   Ridge Regression  4077.913440  0.558653
2   Lasso Regression  4081.260581  0.557126
0  Linear Regression  4081.271170  0.557122
```

5. O melhor modelo foi identificado com base no menor RMSE.

A compara√ß√£o entre os modelos de Regress√£o Linear, Ridge e Lasso, realizada por meio de valida√ß√£o cruzada com 5 folds, mostrou que o Ridge Regression apresentou o melhor desempenho, obtendo o menor valor de RMSE m√©dio e o maior R¬≤ m√©dio.

No entanto, a diferen√ßa entre os modelos foi relativamente pequena, indicando que todos apresentaram comportamentos semelhantes ao modelar a rela√ß√£o entre enginesize e price. Esse resultado sugere que, ao utilizar apenas uma √∫nica vari√°vel explicativa, o impacto da regulariza√ß√£o √© limitado.

Ainda assim, o Ridge Regression demonstrou maior estabilidade e capacidade de generaliza√ß√£o, o que justifica sua escolha como o melhor modelo entre os avaliados. Esses resultados refor√ßam a import√¢ncia da regulariza√ß√£o, mesmo quando os ganhos de desempenho s√£o sutis.

---

## Quest√£o 4 ‚Äì Coeficientes e Sele√ß√£o de Atributos

**Arquivo:** `regressao_q4.py`

Na etapa final do projeto, foi utilizada a Regress√£o Lasso com o objetivo de analisar a import√¢ncia das vari√°veis explicativas e identificar quais atributos possuem maior influ√™ncia na previs√£o do pre√ßo dos ve√≠culos.

Diferentemente da regress√£o linear tradicional, o Lasso aplica regulariza√ß√£o L1, que tende a reduzir coeficientes menos relevantes, podendo inclusive zer√°-los, tornando-se uma ferramenta eficaz para sele√ß√£o de atributos.

1. Sele√ß√£o das vari√°veis mais revelantes.

Para esta an√°lise, foram selecionadas tr√™s vari√°veis explicativas:
* enginesize
* carheight
* horsepower

Essas vari√°veis foram escolhidas com base na an√°lise de correla√ß√£o e em sua relev√¢ncia t√©cnica para a forma√ß√£o do pre√ßo dos ve√≠culos.


2. Padroniza√ß√£o dos Dados.

Antes do treinamento do modelo Lasso, os dados foram padronizados utilizando o StandardScaler. Essa etapa √© fundamental, pois a regress√£o Lasso √© sens√≠vel √† escala das vari√°veis. A padroniza√ß√£o garante que todas as vari√°veis tenham m√©dia zero e desvio padr√£o igual a um, permitindo uma compara√ß√£o justa entre os coeficientes.

3. Treinamento do Modelo Lasso.

O modelo Lasso foi treinado utilizando o par√¢metro de regulariza√ß√£o Œ± = 0.1, valor que equilibra a penaliza√ß√£o dos coeficientes sem eliminar completamente vari√°veis relevantes.

Ap√≥s o treinamento, os coeficientes associados a cada atributo foram extra√≠dos para an√°lise.

4.An√°lise dos Coeficientes 

Os coeficientes obtidos pelo modelo Lasso foram organizados em um DataFrame, juntamente com seus valores absolutos, permitindo avaliar a import√¢ncia relativa de cada vari√°vel.

![Inport√¢ncia dos atributos](imagem/inport√¢ncia_atributos.png).

O atributo enginesize apresentou o maior coeficiente absoluto, indicando que o tamanho do motor √© o fator mais influente entre os avaliados para a determina√ß√£o do pre√ßo dos ve√≠culos. Esse resultado √© consistente com as an√°lises anteriores de correla√ß√£o e regress√£o linear simples, refor√ßando a import√¢ncia dessa vari√°vel.

Em segundo lugar, horsepower tamb√©m apresentou uma contribui√ß√£o significativa, mostrando que a pot√™ncia do motor exerce um impacto relevante no pre√ßo, embora inferior ao tamanho do motor.

A vari√°vel carheight, apesar de apresentar influ√™ncia positiva, teve uma import√¢ncia consideravelmente menor quando comparada √†s demais, indicando que seu efeito sobre o pre√ßo √© mais limitado dentro do conjunto de vari√°veis analisadas.

---

## Conclus√£o 

Neste projeto, foi realizada a an√°lise do dataset Car Price Prediction com o objetivo de prever o pre√ßo de ve√≠culos a partir de suas caracter√≠sticas. Ap√≥s o tratamento dos dados, foram aplicados modelos de Regress√£o Linear Simples, Linear M√∫ltipla, Ridge e Lasso.

Os resultados mostraram que a vari√°vel enginesize possui forte influ√™ncia no pre√ßo dos ve√≠culos. Entre os modelos avaliados, o Ridge Regression apresentou o melhor desempenho, indicando que a regulariza√ß√£o contribui para melhorar a generaliza√ß√£o do modelo. A an√°lise com Lasso tamb√©m permitiu identificar as vari√°veis mais importantes para a previs√£o, refor√ßando a consist√™ncia dos resultados obtidos.

O projeto demonstra a aplica√ß√£o pr√°tica de t√©cnicas de regress√£o e valida√ß√£o de modelos, servindo como base para estudos mais avan√ßados em previs√£o de pre√ßos.

---

Projeto desenvolvido para fins acad√™micos e aprendizado em Machine Learning.
