# Projeto de Regress√£o Linear, Ridge e Lasso

Este projeto tem como objetivo aplicar t√©cnicas de **regress√£o linear** para prever o pre√ßo de ve√≠culos, seguindo uma sequ√™ncia estruturada de pr√©-processamento, modelagem, avalia√ß√£o e interpreta√ß√£o dos resultados. O trabalho foi desenvolvido com base no dataset Car Price Prediction, disponibilizado no Kaggle. O foco do projeto n√£o √© uma an√°lise explorat√≥ria aprofundada, mas sim compreender o dataset, preparar os dados corretamente,
aplicar um modelo de regress√£o linear, avaliar seu desempenho, e visualizar a rela√ß√£o entre a vari√°vel mais correlacionada e o pre√ßo.

---

## üìÅ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ preprocessamento.py           # Pr√©-processamento e correla√ß√£o
‚îú‚îÄ‚îÄ regressao_linear_simples.py   # Regress√£o linear simples
‚îú‚îÄ‚îÄ linear_ridge_lasso.py         # Linear vs Ridge vs Lasso
‚îú‚îÄ‚îÄ coeficientes.py               # Coeficientes e sele√ß√£o de atributos
‚îú‚îÄ‚îÄ regressao_ajustado.csv
‚îî‚îÄ‚îÄ README.md
```

---
## üìÇ Dataset

Fonte: Kaggle

Link: https://www.kaggle.com/datasets/hellbuoy/car-price-prediction

Nome do arquivo original: CarPrice_Assignment.csv

O dataset cont√©m informa√ß√µes de diferentes autom√≥veis, incluindo caracter√≠sticas como:

* tipo de combust√≠vel

* tamanho do motor

* pot√™ncia

* consumo

* dimens√µes do ve√≠culo

* pre√ßo (vari√°vel alvo)

---

## Bibliotecas utilizadas

Este projeto foi desenvolvido em Python utilizando bibliotecas amplamente empregadas em an√°lise de dados e aprendizado de m√°quina, conforme descrito abaixo:

---

Pandas: Biblioteca utilizada para carregamento, manipula√ß√£o e an√°lise de dados tabulares.
Permite ler arquivos CSV, tratar colunas, selecionar vari√°veis e realizar an√°lises estat√≠sticas b√°sicas.
```python
import pandas as pd
```
Matplotlib: Biblioteca fundamental para cria√ß√£o de gr√°ficos em Python.
Foi utilizada para plotar gr√°ficos de dispers√£o, retas de regress√£o e gr√°ficos de import√¢ncia dos atributos.
```python
import seaborn as pd
```
Seaborn: Biblioteca de visualiza√ß√£o estat√≠stica baseada no matplotlib.
Facilita a cria√ß√£o de gr√°ficos mais elegantes, como mapas de correla√ß√£o, boxplots e distribui√ß√µes.
```python
import matplotlib.pyplot as plt
```
NumPy: Biblioteca fundamental para opera√ß√µes num√©ricas e matem√°ticas em Python.
Foi utilizada para c√°lculos como o RMSE, manipula√ß√£o de arrays e opera√ß√µes vetoriais.
```python
import numpy as np
```
train_test_split: Fun√ß√£o do scikit-learn utilizada para dividir o dataset em conjuntos de treino e teste, garantindo uma avalia√ß√£o adequada do modelo.
```python
from sklearn.model_selection import train_test_split
```
StandardScaler: Utilizada para padroniza√ß√£o dos dados num√©ricos, fazendo com que todas as vari√°veis tenham m√©dia 0 e desvio padr√£o 1.
Essa etapa √© essencial para modelos sens√≠veis √† escala, como Ridge e Lasso.
```python
from sklearn.preprocessing import StandardScaler
```
LinearRegression: Modelo de Regress√£o Linear do scikit-learn.
Foi aplicado tanto na regress√£o linear simples quanto na regress√£o linear m√∫ltipla.
```python
from sklearn.linear_model import LinearRegression
```
Ridge Regression: Modelo de regress√£o linear com regulariza√ß√£o L2, utilizado para reduzir overfitting e controlar a magnitude dos coeficientes.
```python
from sklearn.linear_model import Ridge
```
Lasso Regression: Modelo de regress√£o linear com regulariza√ß√£o L1, capaz de zerar coeficientes, sendo √∫til para sele√ß√£o de atributos e an√°lise de import√¢ncia das vari√°veis.
```python
from sklearn.linear_model import Lasso
```
cross_val_score: Fun√ß√£o utilizada para aplicar valida√ß√£o cruzada (cross-validation), permitindo avaliar o desempenho dos modelos de forma mais robusta.
```python
from sklearn.model_selection import cross_val_score
```
M√©tricas de Avalia√ß√£o: Foram utilizadas m√©tricas para avaliar o desempenho dos modelos de regress√£o:
RMSE (Root Mean Squared Error): mede o erro m√©dio das previs√µes.
R¬≤ (Coeficiente de Determina√ß√£o): indica o quanto o modelo explica a variabilidade da vari√°vel alvo.
```python
from sklearn.metrics import mean_squared_error, r2_score
```

---

## Pr√©-processamento e Correla√ß√£o

**Arquivo:** `preprocessamento.py`

Nesta etapa inicial, foi realizado o preparo dos dados para a modelagem:

1. O dataset original foi carregado.
Inicialmente, o dataset bruto foi carregado utilizando a biblioteca Pandas, e foram realizadas inspe√ß√µes b√°sicas para compreender sua estrutura:
* Visualiza√ß√£o das primeiras linhas do dataset (head)
* Verifica√ß√£o dos tipos de dados de cada coluna
* Verifica√ß√£o de valores ausentes (missing values)
Essa etapa permitiu confirmar que o dataset n√£o possui valores nulos, eliminando a necessidade de t√©cnicas de imputa√ß√£o.

2. Tratamento de vari√°veis categ√≥ricas
O dataset cont√©m diversas vari√°veis categ√≥ricas, como tipo de combust√≠vel, carroceria, tipo de motor e sistema de combust√≠vel. Como modelos de regress√£o n√£o trabalham diretamente com dados categ√≥ricos em formato textual, foi necess√°rio convert√™-los para valores num√©ricos.
As seguintes colunas categ√≥ricas foram identificadas:
* CarName
* fueltype
* aspiration
* doornumber
* carbody
* drivewheel
* enginelocation
* enginetype
* cylindernumber
* fuelsystem
Para isso, foi utilizado o m√©todo `pd.factorize()`, que transforma cada categoria em um valor inteiro √∫nico. Esse m√©todo foi escolhido por ser simples e suficiente para esta etapa explorat√≥ria e de modelagem inicial.
Ap√≥s a convers√£o, todas as colunas do dataset passaram a possuir valores num√©ricos.

3. An√°lise de Correla√ß√£o e matriz de correla√ß√£o entre as vari√°veis num√©ricas e a vari√°vel-alvo (`price`).
Com os dados totalmente num√©ricos, foi realizada uma an√°lise de correla√ß√£o entre todas as vari√°veis e a vari√°vel alvo price.
Essa an√°lise teve como objetivo:
Identificar quais atributos possuem maior rela√ß√£o com o pre√ßo dos ve√≠culos
Auxiliar na sele√ß√£o das vari√°veis mais relevantes para os modelos de regress√£o
As correla√ß√µes foram ordenadas de forma decrescente, permitindo identificar rapidamente as vari√°veis mais correlacionadas positiva ou negativamente com o pre√ßo.

```
Correla√ß√£o das vari√°veis com Price:
 price               1.000000
enginesize          0.874145
curbweight          0.835305
horsepower          0.808139
carwidth            0.759325
carlength           0.682920
...                   ...
fuelsystem         -0.122118
drivewheel         -0.577992
citympg            -0.685751
highwaympg         -0.697599
```
Al√©m da correla√ß√£o individual com a vari√°vel alvo, foi constru√≠da uma matriz de correla√ß√£o completa, considerando todas as colunas num√©ricas do dataset.
Foi utilizado o m√©todo de correla√ß√£o Spearman, por ser mais robusto a rela√ß√µes n√£o lineares e valores extremos.

![Matriz de Correla√ß√£o](images/matriz_correla√ß√£o.png)



4. Com base na correla√ß√£o, foi poss√≠vel identificar quais atributos possuem maior rela√ß√£o com o pre√ßo.
5. Os dados num√©ricos foram padronizados utilizando o `StandardScaler`, garantindo m√©dia zero e desvio padr√£o igual a um.
6. O dataset final pr√©-processado foi salvo no arquivo `regressao_ajustado.csv`.

Essa etapa √© fundamental para garantir qualidade dos dados e evitar vieses nos modelos.

---

## Quest√£o 2 ‚Äì Regress√£o Linear Simples

**Arquivo:** `regressao_q2.py`

Nesta etapa, foi aplicada a regress√£o linear simples com o objetivo de entender a rela√ß√£o entre uma vari√°vel explicativa e o pre√ßo:

1. Foi utilizado o modelo de **Regress√£o Linear** da biblioteca `scikit-learn`.
2. A vari√°vel mais correlacionada com o pre√ßo foi escolhida para o modelo.
3. Um gr√°fico foi gerado exibindo os pontos reais e a reta de regress√£o ajustada.
4. O desempenho do modelo foi avaliado utilizando as m√©tricas **RMSE** e **R¬≤**.
5. Os resultados foram analisados, permitindo interpretar o poder explicativo do modelo simples.

Essa an√°lise fornece uma visualiza√ß√£o clara da rela√ß√£o linear entre a vari√°vel escolhida e o pre√ßo.

---

## Quest√£o 3 ‚Äì Compara√ß√£o: Linear vs Ridge vs Lasso

**Arquivo:** `regressao_q3.py`

Nesta fase, o objetivo foi comparar diferentes modelos de regress√£o:

1. Foram aplicados tr√™s modelos: **Regress√£o Linear**, **Ridge** e **Lasso**.
2. Foi utilizada **valida√ß√£o cruzada com 5 folds** (`cross_val_score`) para obter m√©tricas mais robustas.
3. As m√©tricas **RMSE m√©dio** e **R¬≤ m√©dio** foram calculadas para cada modelo.
4. Os resultados foram organizados em uma tabela comparativa.
5. O melhor modelo foi identificado com base no menor RMSE.

Essa compara√ß√£o evidencia o impacto da regulariza√ß√£o no desempenho dos modelos.

---

## Quest√£o 4 ‚Äì Coeficientes e Sele√ß√£o de Atributos

**Arquivo:** `regressao_q4.py`

Por fim, foi realizada a an√°lise de import√¢ncia das vari√°veis utilizando o modelo Lasso:

1. Os dados foram padronizados antes do treinamento do modelo Lasso.
2. Os coeficientes aprendidos pelo modelo foram extra√≠dos.
3. Foi calculada a import√¢ncia absoluta de cada atributo.
4. Um gr√°fico de barras horizontais foi gerado para visualizar a import√¢ncia dos atributos.
5. Os resultados foram discutidos, destacando quais vari√°veis t√™m maior impacto na previs√£o do pre√ßo.

O Lasso mostrou-se eficiente para sele√ß√£o autom√°tica de atributos, reduzindo a influ√™ncia de vari√°veis menos relevantes.

---

## üìä Conclus√£o

O projeto demonstrou, de forma pr√°tica, todo o fluxo de uma an√°lise de regress√£o:

* Pr√©-processamento adequado dos dados;
* Aplica√ß√£o de regress√£o linear simples e m√∫ltipla;
* Compara√ß√£o entre modelos com e sem regulariza√ß√£o;
* Interpreta√ß√£o dos coeficientes e sele√ß√£o de atributos relevantes.

Os resultados obtidos indicam que modelos regularizados, como o Ridge e o Lasso, podem melhorar a generaliza√ß√£o e fornecer insights importantes sobre a relev√¢ncia das vari√°veis.

---

## üõ†Ô∏è Tecnologias Utilizadas

* Python
* Pandas
* NumPy
* Matplotlib
* Scikit-learn

---

Projeto desenvolvido para fins acad√™micos e aprendizado em Machine Learning.
